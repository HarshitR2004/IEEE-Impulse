{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f75f194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T21:53:17.412001Z",
     "iopub.status.busy": "2025-01-18T21:53:17.411683Z",
     "iopub.status.idle": "2025-01-18T21:53:18.940094Z",
     "shell.execute_reply": "2025-01-18T21:53:18.938981Z"
    },
    "papermill": {
     "duration": 1.533841,
     "end_time": "2025-01-18T21:53:18.941954",
     "exception": false,
     "start_time": "2025-01-18T21:53:17.408113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class EEGFeatureExtractor:\n",
    "    def __init__(self, signals=None, sampling_rate=256):\n",
    "        \"\"\"Initialize EEGFeatureExtractor with EEG signals and sampling rate.\"\"\"\n",
    "        self.signals = signals\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "    def extract_time_domain_features(self):\n",
    "        \"\"\"Extract time domain features from EEG signals.\n",
    "        Args:\n",
    "            signals: Shape (samples, channels, time_points)\n",
    "        Returns:\n",
    "            features: Shape (samples, n_features)\n",
    "        \"\"\"\n",
    "        n_samples = self.signals.shape[0]\n",
    "        features_list = []\n",
    "        \n",
    "        for sample in range(n_samples):\n",
    "            sample_features = []\n",
    "            for channel in range(self.signals.shape[1]):\n",
    "                channel_signal = self.signals[sample, channel, :]\n",
    "                \n",
    "                # Basic statistics\n",
    "                mean = np.mean(channel_signal)\n",
    "                std = np.std(channel_signal)\n",
    "                max_val = np.max(channel_signal)\n",
    "                min_val = np.min(channel_signal)\n",
    "                \n",
    "                # Zero crossing rate\n",
    "                zero_crossings = np.sum(np.abs(np.diff(np.signbit(channel_signal))))\n",
    "                \n",
    "                # Activity measures\n",
    "                rms = np.sqrt(np.mean(channel_signal**2))\n",
    "                mean_abs = np.mean(np.abs(channel_signal))\n",
    "                \n",
    "                # Shape statistics\n",
    "                kurtosis = stats.kurtosis(channel_signal)\n",
    "                skewness = stats.skew(channel_signal)\n",
    "                \n",
    "                # Hjorth parameters\n",
    "                diff_first = np.diff(channel_signal)\n",
    "                diff_second = np.diff(diff_first)\n",
    "                mobility = np.std(diff_first) / np.std(channel_signal)\n",
    "                complexity = np.std(diff_second) / np.std(diff_first)\n",
    "                \n",
    "                channel_features = [\n",
    "                    mean, std, max_val, min_val, zero_crossings,\n",
    "                    rms, mean_abs, kurtosis, skewness,\n",
    "                    mobility, complexity\n",
    "                ]\n",
    "                sample_features.extend(channel_features)\n",
    "            \n",
    "            features_list.append(sample_features)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "\n",
    "    def extract_frequency_domain_features(self):\n",
    "        \"\"\"Extract frequency domain features from EEG signals.\n",
    "        Args:\n",
    "            signals: Shape (samples, channels, time_points)\n",
    "            sampling_rate: Sampling frequency in Hz\n",
    "        Returns:\n",
    "            features: Shape (samples, n_features)\n",
    "        \"\"\"\n",
    "        n_samples = self.signals.shape[0]\n",
    "        features_list = []\n",
    "        \n",
    "        # Define frequency bands\n",
    "        bands = {\n",
    "            'delta': (0.5, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 13),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 45)\n",
    "        }\n",
    "        \n",
    "        for sample in range(n_samples):\n",
    "            sample_features = []\n",
    "            for channel in range(self.signals.shape[1]):\n",
    "                channel_signal = self.signals[sample, channel, :]\n",
    "                \n",
    "                # Compute power spectral density\n",
    "                freqs, psd = welch(channel_signal, fs=self.sampling_rate)\n",
    "                \n",
    "                # Calculate band powers\n",
    "                band_powers = {}\n",
    "                for band_name, (low, high) in bands.items():\n",
    "                    mask = (freqs >= low) & (freqs <= high)\n",
    "                    band_powers[band_name] = np.mean(psd[mask])\n",
    "                \n",
    "                # Spectral edge frequency (95% of power)\n",
    "                total_power = np.cumsum(psd)\n",
    "                total_power = total_power / total_power[-1]\n",
    "                spectral_edge = freqs[np.where(total_power >= 0.95)[0][0]]\n",
    "                \n",
    "                channel_features = [\n",
    "                    band_powers['delta'],\n",
    "                    band_powers['theta'],\n",
    "                    band_powers['alpha'],\n",
    "                    band_powers['beta'],\n",
    "                    band_powers['gamma'],\n",
    "                    spectral_edge\n",
    "                ]\n",
    "                sample_features.extend(channel_features)\n",
    "            \n",
    "            features_list.append(sample_features)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "\n",
    "    def extract_connectivity_features(self):\n",
    "        \"\"\"Extract connectivity features between EEG channels.\n",
    "        Args:\n",
    "            signals: Shape (samples, channels, time_points)\n",
    "        Returns:\n",
    "            features: Shape (samples, n_features)\n",
    "        \"\"\"\n",
    "        n_samples = self.signals.shape[0]\n",
    "        features_list = []\n",
    "        \n",
    "        for sample in range(n_samples):\n",
    "            sample_features = []\n",
    "            n_channels = self.signals.shape[1]\n",
    "            \n",
    "            # Cross-correlation and coherence\n",
    "            for i in range(n_channels):\n",
    "                for j in range(i+1, n_channels):\n",
    "                    sig_i = self.signals[sample, i, :]\n",
    "                    sig_j = self.signals[sample, j, :]\n",
    "                    \n",
    "                    # Cross-correlation\n",
    "                    correlation = np.corrcoef(sig_i, sig_j)[0, 1]\n",
    "                    \n",
    "                    # Coherence (simplified)\n",
    "                    coh = np.abs(np.correlate(sig_i, sig_j)).max()\n",
    "                    \n",
    "                    sample_features.extend([correlation, coh])\n",
    "            \n",
    "            features_list.append(sample_features)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "\n",
    "    def extract_wavelet_features(self):\n",
    "        \"\"\"Extract wavelet-based features from EEG signals.\n",
    "        Args:\n",
    "            signals: Shape (samples, channels, time_points)\n",
    "        Returns:\n",
    "            features: Shape (samples, n_features)\n",
    "        \"\"\"\n",
    "        n_samples = self.signals.shape[0]\n",
    "        features_list = []\n",
    "        wavelet = 'db4'\n",
    "        level = 4\n",
    "        \n",
    "        for sample in range(n_samples):\n",
    "            sample_features = []\n",
    "            for channel in range(self.signals.shape[1]):\n",
    "                channel_signal = self.signals[sample, channel, :]\n",
    "                \n",
    "                # Decompose signal\n",
    "                coeffs = pywt.wavedec(channel_signal, wavelet, level=level)\n",
    "                \n",
    "                # Extract features from each coefficient level\n",
    "                for coeff in coeffs:\n",
    "                    # Statistical features\n",
    "                    feat_mean = np.mean(coeff)\n",
    "                    feat_std = np.std(coeff)\n",
    "                    feat_energy = np.sum(coeff**2)\n",
    "                    \n",
    "                    level_features = [feat_mean, feat_std, feat_energy]\n",
    "                    sample_features.extend(level_features)\n",
    "            \n",
    "            features_list.append(sample_features)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "\n",
    "    def combine_features(self, normalize=True):\n",
    "        \"\"\"Combine all features and optionally normalize.\n",
    "        Args:\n",
    "            signals: Shape (samples, channels, time_points)\n",
    "            normalize: Whether to normalize features\n",
    "        Returns:\n",
    "            features: Shape (samples, n_total_features)\n",
    "        \"\"\"\n",
    "        # Extract all feature types\n",
    "        time_features = self.extract_time_domain_features()\n",
    "        freq_features = self.extract_frequency_domain_features()\n",
    "        wavelet_features = self.extract_wavelet_features()\n",
    "        conn_features = self.extract_connectivity_features()\n",
    "        \n",
    "        # Combine features\n",
    "        all_features = np.concatenate([\n",
    "            time_features,\n",
    "            freq_features,\n",
    "            wavelet_features,\n",
    "            conn_features\n",
    "        ], axis=1)\n",
    "        \n",
    "        if normalize:\n",
    "            scaler = StandardScaler()\n",
    "            all_features = scaler.fit_transform(all_features)\n",
    "        \n",
    "        return all_features\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6499901,
     "sourceId": 10497950,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 218048333,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.638138,
   "end_time": "2025-01-18T21:53:19.464749",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-18T21:53:14.826611",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
